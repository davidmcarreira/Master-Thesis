\documentclass[class=report, crop=false, a4paper, 12pt]{standalone}

%Packages import
\usepackage{../pkgs}


\begin{document}
\section{Main Outcomes}
\par This work studies different neural networks models in order to propose an improved approach to TrustID's facial verification module. The main objective is to find an appropriate trade-off between accurate performance and computational cost, without compromising safety, that substitutes TrustID's FR module. To that extent, based on the state of the art presented, four different models were suggested: MobileFaceNet, FaceNet, iResnet-18 and iResnet-SE-50. Firstly, they were implemented and compared in terms of their specifications: number of trainable parameters, mult-adds, number of trainable layers, embedding size, inference time, loss function and training dataset. Since the system is to be applied on an image-based student monitoring scenario, the capturing device induces high data variations, hence the model must be invariant to poses, illumination, quality, etc. With that in mind, appropriate benchmarks were designed to test the methods in a wide range of possible scenarios.

\par With initial tests, we evaluated some pre-trained models in order to select one to then verify if it could be further refined. Analyzing the accuracies on all benchmarks, the ROC curves, TAR at different FAR values, DET curves and EER points, clearly showcased the best three models that could substitute TrustID's solution: iResnet-SE-50, iResnet-18 and MobileFaceNet. iResnet-SE-50 and iResnet-18 are two contenders that performed similarly and MobileFaceNet consistently scored third, but at a close distance. Balancing MobileFaceNet's performance with its inherent lightweight characteristics, it was selected for fine-tuning, since it has much less trainable parameters, number of mult-adds operations, inference time and NPUA for a minimal performance trade-off.

\par Two datasets were chosen for fine-tuning, each one with an objective in mind. QMUL-SurvFace was proposed as a way of improving the performance on the very challenging XQLFW benchmark. Then DigiFace-1M was utilized to test how the model would react to fully synthetic ethically sourced data, and if it would improve the performance on pose related benchmarks. First, all the layers of the network, aside from the batch norm ones, were trained for three different ArcFace margins ($0.5$, $0.4$ and $0.3$). This approach revealed to be successful in increasing the XQLFW accuracy performance and discriminative power at lower FAR ($1e-3$ and $1e-2$ for $m=0.5$) for the pose group and XQLFW when trained with QMUL-SurvFace. However, that came along with inferior results on the other benchmarks. In the same experiment, DigiFace-1M did not improve any accuracy results.  

\par With the performance degradation verified on the benchmarks for both datasets, two new training approaches that involved freezing layers were employed. We concluded that, as would be theoretically expected, the lesser layers were trained, the closer the results are to the pre-trained model, but the XQLFW performance did not improve, and again DigiFace-1M did not show any enhancement whatsoever. This behavior also leads us to believe that, since the model trained with less layers still shows performs degradation while not improving in the same domains where the model trained through all the layers does, that can indicate that the model needs to be more complex in order to be able to adapt to the dataset's intricacies without tuning it over all the layers.

\par Moreover, even though it was not the primary focus of this work, with the customization and application of RetinaFace, execution of the face recognition methods and merging them with ArcFace for training, the goal of implementing the essential stages of a face recognition pipeline is achieved. All in all, and most importantly, the main objective is successfully accomplished, MobileFaceNet is an adequate trade-off between computational overhead and accurate results that performs better than TrustID, as proven by the benchmarks and further supported by the NPUA scores.

\section{Future work}
To further improve the current work, there are some open issues that are worth investigating. Following the ethically sourced data philosophy, it is important to train, from scratch, using only DigiFace-1M or an ensemble of datasets of synthetic data and consensual images, in order to compare how the model would perform on the same benchmarks geared toward student monitoring scenarios. For that, MobileFaceNet~\autocite{chenMobileFaceNetsEfficientCNNs2018} is a mandatory option, but others lightweight networks, specially recent ones like ConvFaceNext~\autocite{hooConvFaceNeXtLightweightNetworks2022} or MixFaceNet~\autocite{boutrosMixFaceNetsExtremelyEfficient2021}, must also be considered. Additionally, different training strategies need to be investigated, for example, freezing all the layers and gradually unfreezing them while training, finding the optimal learning rate and scheduler per layer or employing different loss functions, such as QMagFace~\autocite{terhorstQMagFaceSimpleAccurate2023}. Furthermore, leveraging the real world webcam data collected during TrustID's proof of concepts, a private face verification dataset and protocol is to be designed to further aid the system's development. Finally, implementing an additional measure against fraud, in particular, liveness detection would also highly benefit the system's robustness. 

\end{document}