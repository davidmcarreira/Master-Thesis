\documentclass[class=report, crop=false, a4paper, 12pt]{standalone}

%Packages import
\usepackage{../pkgs}


\begin{document}
\par A pandemia de COVID-19 forçou os sistemas educacionais a fazerem uma rápida transição para aulas remotas, gerando um debate sobre a credibilidade das avaliações, visto que estas se tornaram mais suscetíveis a fraudes. Isto motivou a implementação de sistemas de monitorização de estudantes, tal como o TrustID, que é uma solução, baseada em imagens, de aprendizagem profunda, constituída pelas etapas padrão de um sistema de reconhecimento facial (detecção do rosto, alinhamento e representação). No entanto, o desempenho dos métodos de aprendizagem profunda é extremamente dependente da informação ao seu dispor e, devido ao contexto em que o modelo é aplicado, dependendo do dispositivo utilizado pelo estudante, surgem desafios relacionados com qualidade dos dados adquiridos e a capacidade de processamento disponível do dispositivo. Se o aluno utilizar uma webcam ou a câmara frontal de um telemóvel, as imagens resultantes serão muito diferentes em termos de resolução, cor, pose, etc. Nesse sentido, a etapa de representação facial é onde há mais espaço para melhorias, e uma abordagem capaz de lidar com os desafios anteriores com melhor equilíbrio entre exatidão e custo computacional é explorada. Este trabalho estuda quatro métodos de Redes Neurais Profundas de Convolução (DCNN) pré-treinadas: iResnet-SE-50, iResnet-18, FaceNet e MobileFaceNet. Após serem submetidos a diferentes testes de avaliação que simulam cenários do mundo real, os resultados e as métricas de exatidão/utilização de recursos são analisados, onde o MobileFaceNet demonstra ter, globalmente, a melhor relação entre exatidão e recursos computacionais. Em seguida, na tentativa de melhorar ainda mais o modelo, este é afinado com o ArcFace usando diferentes estratégias de congelamento de camadas e, para isso, dois conjuntos de imagens foram selecionados: DigiFace-1M e QMUL-SurvFace. O DigiFace-1M visa compreender como o modelo reage a dados totalmente sintéticos e melhorar o desempenho do modelo em benchmarks de pose, enquanto que o QMUL-SurvFace é selecionado para aprimorar a competência do modelo em imagens de baixa qualidade.

\end{document}
