\documentclass[class=report, crop=false, a4paper, 12pt]{standalone}

%Packages import
\usepackage{../pkgs}


\begin{document}
\section{Fundamentals}

% - Computer Vision definition
% - Natural Language Processing definition
% - Hyperparameters 

% - Machine Learning: 
%   - Shallow Leaning vs Deep Learning => Concluding why DL is better
%   - Conventional Machine Learning vs Deep Learning:
%     - Examples of both topics' applications

% - Convolutional Neural Networks:
%   - Small description of why CNNs are important/different from other networks
%   - The architecture of a CNN + what each layer does
%   - Examples of CNN applications
%
% - Facial recognition, facial detection and facial identification


%Paragraph describing what a CNN is and roughly how it works
There are several types of Neural Networks architectures, but Convolutional Neural Networks (CNNs or Convnets) are probably the most widely implemented model overall \autocite{yamashitaConvolutionalNeuralNetworks2018, liSurveyConvolutionalNeural2022} with successful applications in the domains of Computer Vision \autocite{krizhevskyImageNetClassificationDeep2012,taigmanDeepFaceClosingGap2014,tompsonEfficientObjectLocalization2015, zhangImprovedBreastCancer2021} or Natural Language Processing\autocite{abdel-hamidConvolutionalNeuralNetworks2014, wangGenCNNConvolutionalArchitecture2015, xiangConvolutionalNeuralNetworkbased2020}. In the CNN category itself there are different variants, but they all abide the fundamental structure of a feedforward hierarchical multi-layer network. Feedforward because the information only flows in a singular direction without cycling \autocite{zellSimulationNeuronalerNetze1994}, hierarchical because the higher complexity internal representations are learned from lower ones \autocite{lecunDeepLearning2015, zhuBCNNBranchConvolutional2017} and multi-layer because it is composed of a series of stages, blocks or layers: the raw data is fed to an input layer, forwarded to a sequence of intercalating convolutional and pooling layers, proceeded to a stage of one or more fully-connected layers \autocite{lecunDeepLearning2015, yamashitaConvolutionalNeuralNetworks2018, guRecentAdvancesConvolutional2018, alzubaidiReviewDeepLearning2021}.

%Why using them for Computer Vision
\par Using CNNs for Computer Vision tasks is not an arbitrary choice, but due to the fact that the network design can benefit from the intrinsic characteristics of the input data \autocite{lecunDeepLearning2015} they perform really well in image related applications. In the first place, images have an array-like structure with numerous elements, namely, each pixel has an assigned value organized in a grid like manner \autocite{yamashitaConvolutionalNeuralNetworks2018}, matching the type of input for these networks \autocite{lecunDeepLearning2015}. In the second place, there's an inherent correlation between local groups of values, which creates distinguishable motifs. Finally, the local values of images are invariant to location, that is, a certain composition should have the same value independently of the spatial location in the picture. 



This model architecture is based on the visual cortex ventral pathway, therefore, it is capable of automatically extracting spatial feature hierarchies, from a lower to higher complexity (in contrast to conventional machine learning) \autocite{lecunDeepLearning2015,yamashitaConvolutionalNeuralNetworks2018,guRecentAdvancesConvolutional2018,alzubaidiReviewDeepLearning2021}.


Key features such as local connections/receptive fields, shared weights, sub-sampling and the use of many layers allows this network to be invariant to shift, scale and distortions.

% Why CNN:
% - Automatically identifies the relevant features without any human supervision \autocite{alzubaidiReviewDeepLearning2021, yamashitaConvolutionalNeuralNetworks2018, liSurveyConvolutionalNeural2022} 
% - Little to none preprocessing \autocite{guRecentAdvancesConvolutional2018}
% - Designed for multi-array data \autocite{lecunDeepLearning2015}
% - Units at different locations share the same weights and detect the same pattern in different parts of the array \autocite{lecunDeepLearning2015}
% - Invariance to small shifts, distortions rotations due to the pooling layer \autocite{lecunDeepLearning2015}
% - Many layers, increase the depth, therefore the netweork can better approximate the target function with increased nonlinearity and get better feature representations. \autocite{guRecentAdvancesConvolutional2018}


%Subsections describing what each layer does (probably mentioning some optional ones)


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% In digital images, pixel values are stored in a two-dimensional (2D) grid, i.e., an array of numbers (Fig. 2), and a small grid of parameters called kernel, an optimizable feature extractor, is applied at each image position, which makes CNNs highly efficient for image processing, since a feature may occur anywhere in the image.

%The input layer holds the raw pixel values of the image; the convolutional layer computes the output of nodes that are connected to local regions in the input layer; the pooling layer performs the down-sampling operation along the spatial dimensions; the fully-connected layer computes the class scores; and the output layer gives the final results. In this way, we can create a deep architecture by alternately stacking the convolutional layer and pooling layer. \autocite{caoReviewNeuralNetworks2018}


\end{document}