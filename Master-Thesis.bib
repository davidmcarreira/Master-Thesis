@article{4308320,
  title = {Polynomial Theory of Complex Systems},
  author = {Ivakhnenko, A. G.},
  year = {1971},
  journal = {IEEE Transactions on Systems, Man, and Cybernetics},
  volume = {SMC-1},
  number = {4},
  pages = {364--378},
  doi = {10.1109/TSMC.1971.4308320}
}

@article{6795724,
  title = {Backpropagation Applied to Handwritten Zip Code Recognition},
  author = {LeCun, Y. and Boser, B. and Denker, J. S. and Henderson, D. and Howard, R. E. and Hubbard, W. and Jackel, L. D.},
  year = {1989},
  journal = {Neural Computation},
  volume = {1},
  number = {4},
  pages = {541--551},
  doi = {10.1162/neco.1989.1.4.541}
}

@article{abdel-hamidConvolutionalNeuralNetworks2014,
  title = {Convolutional {{Neural Networks}} for {{Speech Recognition}}},
  author = {{Abdel-Hamid}, Ossama and Mohamed, Abdel-rahman and Jiang, Hui and Deng, Li and Penn, Gerald and Yu, Dong},
  year = {2014},
  month = oct,
  journal = {IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  volume = {22},
  number = {10},
  pages = {1533--1545},
  issn = {2329-9304},
  doi = {10.1109/TASLP.2014.2339736},
  abstract = {Recently, the hybrid deep neural network (DNN)-hidden Markov model (HMM) has been shown to significantly improve speech recognition performance over the conventional Gaussian mixture model (GMM)-HMM. The performance improvement is partially attributed to the ability of the DNN to model complex correlations in speech features. In this paper, we show that further error rate reduction can be obtained by using convolutional neural networks (CNNs). We first present a concise description of the basic CNN and explain how it can be used for speech recognition. We further propose a limited-weight-sharing scheme that can better model speech features. The special structure such as local connectivity, weight sharing, and pooling in CNNs exhibits some degree of invariance to small shifts of speech features along the frequency axis, which is important to deal with speaker and environment variations. Experimental results show that CNNs reduce the error rate by 6\%-10\% compared with DNNs on the TIMIT phone recognition and the voice search large vocabulary speech recognition tasks.},
  keywords = {Convolution,convolutional neural networks,Hidden Markov models,Limited Weight Sharing (LWS) scheme,Neural networks,pooling,Speech,Speech recognition,Training,Vectors},
  file = {/home/david/Zotero/storage/2GDDFR8V/Abdel-Hamid et al. - 2014 - Convolutional Neural Networks for Speech Recogniti.pdf;/home/david/Zotero/storage/HWAB7EPQ/stamp.html}
}

@inproceedings{ajitReviewConvolutionalNeural2020,
  title = {A {{Review}} of {{Convolutional Neural Networks}}},
  booktitle = {2020 {{International Conference}} on {{Emerging Trends}} in {{Information Technology}} and {{Engineering}} (Ic-{{ETITE}})},
  author = {Ajit, Arohan and Acharya, Koustav and Samanta, Abhishek},
  year = {2020},
  month = feb,
  pages = {1--5},
  doi = {10.1109/ic-ETITE47903.2020.049},
  abstract = {Before Convolutional Neural Networks gained popularity, computer recognition problems involved extracting features out of the data provided which was not adequately efficient or provided a high degree of accuracy. However in recent times, Convolutional Neural Networks have attempted to provide a higher level of efficiency and accuracy in all the fields in which it has been employed in most popular of which are Object Detection, Digit and Image Recognition. It employs a definitely algorithm of steps to follow including methods like Backpropagation, Convolutional Layers, Feature formation and Pooling. Also this article will also venture into use of various frameworks and tools that involve CNN model.},
  keywords = {Convolutional Neural Networks,Deep Learning,Digit Recognition},
  file = {/home/david/Zotero/storage/HGXLEVHN/Ajit et al. - 2020 - A Review of Convolutional Neural Networks.pdf;/home/david/Zotero/storage/GBMMLPKG/stamp.html}
}

@article{alzubaidiReviewDeepLearning2021,
  title = {Review of Deep Learning: Concepts, {{CNN}} Architectures, Challenges, Applications, Future Directions},
  shorttitle = {Review of Deep Learning},
  author = {Alzubaidi, Laith and Zhang, Jinglan and Humaidi, Amjad J. and {Al-Dujaili}, Ayad and Duan, Ye and {Al-Shamma}, Omran and Santamar{\'i}a, J. and Fadhel, Mohammed A. and {Al-Amidie}, Muthana and Farhan, Laith},
  year = {2021},
  month = mar,
  journal = {Journal of Big Data},
  volume = {8},
  number = {1},
  pages = {53},
  issn = {2196-1115},
  doi = {10.1186/s40537-021-00444-8},
  abstract = {In the last few years, the deep learning (DL) computing paradigm has been deemed the Gold Standard in the machine learning (ML) community. Moreover, it has gradually become the most widely used computational approach in the field of ML, thus achieving outstanding results on several complex cognitive tasks, matching or even beating those provided by human performance. One of the benefits of DL is the ability to learn massive amounts of data. The DL field has grown fast in the last few years and it has been extensively used to successfully address a wide range of traditional applications. More importantly, DL has outperformed well-known ML techniques in many domains, e.g., cybersecurity, natural language processing, bioinformatics, robotics and control, and medical information processing, among many others. Despite it has been contributed several works reviewing the State-of-the-Art on DL, all of them only tackled one aspect of the DL, which leads to an overall lack of knowledge about it. Therefore, in this contribution, we propose using a more holistic approach in order to provide a more suitable starting point from which to develop a full understanding of DL. Specifically, this review attempts to provide a more comprehensive survey of the most important aspects of DL and including those enhancements recently added to the field. In particular, this paper outlines the importance of DL, presents the types of DL techniques and networks. It then presents convolutional neural networks (CNNs) which the most utilized DL network type and describes the development of CNNs architectures together with their main features, e.g., starting with the AlexNet network and closing with the High-Resolution network (HR.Net). Finally, we further present the challenges and suggested solutions to help researchers understand the existing research gaps. It is followed by a list of the major DL applications. Computational tools including FPGA, GPU, and CPU are summarized along with a description of their influence on DL. The paper ends with the evolution matrix, benchmark datasets, and summary and conclusion.},
  keywords = {Convolution neural network (CNN),Deep learning,Deep learning applications,Deep neural network architectures,FPGA,GPU,Image classification,Machine learning,Medical image analysis,Supervised learning,Transfer learning},
  file = {/home/david/Zotero/storage/ATPK2EMH/Alzubaidi et al. - 2021 - Review of deep learning concepts, CNN architectur.pdf;/home/david/Zotero/storage/ZQEACNRQ/s40537-021-00444-8.html}
}

@article{ansariHumanDetectionTechniques2021,
  title = {Human Detection Techniques for Real Time Surveillance: A Comprehensive Survey},
  shorttitle = {Human Detection Techniques for Real Time Surveillance},
  author = {Ansari, Mohd. Aquib and Singh, Dushyant Kumar},
  year = {2021},
  month = mar,
  journal = {Multimedia Tools and Applications},
  volume = {80},
  number = {6},
  pages = {8759--8808},
  issn = {1380-7501, 1573-7721},
  doi = {10.1007/s11042-020-10103-4},
  abstract = {Real-time detection of humans is an evolutionary research topic. It is an essential and prominent component of various vision based applications. Detection of humans in real-time video sequences is an arduous and challenging task due to various constraints like cluttered environment, occlusion, noise, etc. Many researchers are doing their research in this area and have published the number of researches so far. Determining humans in visual monitoring system is prominent for different types of applications like person detection and identification, fall detection for an elder person, abnormal surveillance, gender classification, crowd analysis, person gait characterization, etc. The main objective of this paper is to provide a comprehensive survey of the various challenges and modern developments seen for human detection methodologies in day vision. This paper consists of an overview of different human detection techniques and their classification based on various underlying factors. The algorithmic technicalities with their applicability to these techniques are deliberated in detail in the manuscript. Different humanitarian imperative factors have also been highlighted for comparative analysis of each human detection methodology. Our survey shows the difference between current research and future requirements.},
  langid = {english},
  file = {/home/david/Zotero/storage/TN63GH4G/Ansari and Singh - 2021 - Human detection techniques for real time surveilla.pdf}
}

@article{caoReviewNeuralNetworks2018,
  title = {A Review on Neural Networks with Random Weights},
  author = {Cao, Weipeng and Wang, Xizhao and Ming, Zhong and Gao, Jinzhu},
  year = {2018},
  month = jan,
  journal = {Neurocomputing},
  volume = {275},
  pages = {278--287},
  issn = {0925-2312},
  doi = {10.1016/j.neucom.2017.08.040},
  abstract = {In big data fields, with increasing computing capability, artificial neural networks have shown great strength in solving data classification and regression problems. The traditional training of neural networks depends generally on the error back propagation method to iteratively tune all the parameters. When the number of hidden layers increases, this kind of training has many problems such as slow convergence, time consuming, and local minima. To avoid these problems, neural networks with random weights (NNRW) are proposed in which the weights between the hidden layer and input layer are randomly selected and the weights between the output layer and hidden layer are obtained analytically. Researchers have shown that NNRW has much lower training complexity in comparison with the traditional training of feed-forward neural networks. This paper objectively reviews the advantages and disadvantages of NNRW model, tries to reveal the essence of NNRW, gives our comments and remarks on NNRW, and provides some useful guidelines for users to choose a mechanism to train a feed-forward neural network.},
  langid = {english},
  keywords = {Feed-forward neural networks,Neural networks with random weights,Training mechanism},
  file = {/home/david/Zotero/storage/2DW6TFC3/Cao et al. - 2018 - A review on neural networks with random weights.pdf;/home/david/Zotero/storage/Z7SHKWPE/S0925231217314613.html}
}

@article{chellapillaHighPerformanceConvolutional,
  title = {High {{Performance Convolutional Neural Networks}} for {{Document Processing}}},
  author = {Chellapilla, Kumar and Puri, Sidd and Simard, Patrice},
  abstract = {Convolutional neural networks (CNNs) are well known for producing state-of-the-art recognizers for document processing [1]. However, they can be difficult to implement and are usually slower than traditional multi-layer perceptrons (MLPs). We present three novel approaches to speeding up CNNs: a) unrolling convolution, b) using BLAS (basic linear algebra subroutines), and c) using GPUs (graphic processing units). Unrolled convolution converts the processing in each convolutional layer (both forward-propagation and back-propagation) into a matrix-matrix product. The matrix-matrix product representation of CNNs makes their implementation as easy as MLPs. BLAS is used to efficiently compute matrix products on the CPU. We also present a pixel shader based GPU implementation of CNNs. Results on character recognition problems indicate that unrolled convolution with BLAS produces a dramatic 2.4X-3.0X speedup. The GPU implementation is even faster and produces a 3.1X-4.1X speedup.},
  langid = {english},
  file = {/home/david/Zotero/storage/ZHBI9YQT/Chellapilla et al. - High Performance Convolutional Neural Networks for.pdf}
}

@inproceedings{ciresanCommitteeNeuralNetworks2011,
  title = {A Committee of Neural Networks for Traffic Sign Classification},
  booktitle = {The 2011 {{International Joint Conference}} on {{Neural Networks}}},
  author = {Cire{\c s}an, Dan and Meier, Ueli and Masci, Jonathan and Schmidhuber, J{\"u}rgen},
  year = {2011},
  month = jul,
  pages = {1918--1921},
  issn = {2161-4407},
  doi = {10.1109/IJCNN.2011.6033458},
  abstract = {We describe the approach that won the preliminary phase of the German traffic sign recognition benchmark with a better-than-human recognition rate of 98.98\%.We obtain an even better recognition rate of 99.15\% by further training the nets. Our fast, fully parameterizable GPU implementation of a Convolutional Neural Network does not require careful design of pre-wired feature extractors, which are rather learned in a supervised way. A CNN/MLP committee further boosts recognition performance.},
  keywords = {Biological neural networks,Convolutional codes,Error analysis,Image color analysis,Kernel,Neurons,Training},
  file = {/home/david/Zotero/storage/9VGNNCCB/Cireşan et al. - 2011 - A committee of neural networks for traffic sign cl.pdf;/home/david/Zotero/storage/8QJLFKCB/stamp.html}
}

@article{ciresanDeepBigSimple2010,
  title = {Deep, {{Big}}, {{Simple Neural Nets}} for {{Handwritten Digit Recognition}}},
  author = {Cire{\c s}an, Dan Claudiu and Meier, Ueli and Gambardella, Luca Maria and Schmidhuber, J{\"u}rgen},
  year = {2010},
  month = dec,
  journal = {Neural Computation},
  volume = {22},
  number = {12},
  pages = {3207--3220},
  issn = {0899-7667},
  doi = {10.1162/NECO_a_00052},
  abstract = {Good old online backpropagation for plain multilayer perceptrons yields a very low 0.35\% error rate on the MNIST handwritten digits benchmark. All we need to achieve this best result so far are many hidden layers, many neurons per layer, numerous deformed training images to avoid overfitting, and graphics cards to greatly speed up learning.}
}

@article{ciresanDeepNeuralNetworks2012,
  title = {Deep Neural Networks Segment Neuronal Membranes in Electron Microscopy Images},
  author = {Ciresan, D.C. and Giusti, A. and Gambardella, L.M. and Schmidhuber, J.},
  year = {2012},
  journal = {NIPS},
  volume = {25},
  pages = {2852--2860},
  note = {Export Date: 26 January 2023; Cited By: 92}
}

@inproceedings{ciresanMitosisDetectionBreast2013,
  title = {Mitosis {{Detection}} in {{Breast Cancer Histology Images}} with {{Deep Neural Networks}}},
  booktitle = {Medical {{Image Computing}} and {{Computer-Assisted Intervention}} \textendash{} {{MICCAI}} 2013},
  author = {Cire{\c s}an, Dan C. and Giusti, Alessandro and Gambardella, Luca M. and Schmidhuber, J{\"u}rgen},
  editor = {Mori, Kensaku and Sakuma, Ichiro and Sato, Yoshinobu and Barillot, Christian and Navab, Nassir},
  year = {2013},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {411--418},
  publisher = {{Springer}},
  address = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-642-40763-5_51},
  abstract = {We use deep max-pooling convolutional neural networks to detect mitosis in breast histology images. The networks are trained to classify each pixel in the images, using as context a patch centered on the pixel. Simple postprocessing is then applied to the network output. Our approach won the ICPR 2012 mitosis detection competition, outperforming other contestants by a significant margin.},
  isbn = {978-3-642-40763-5},
  langid = {english},
  keywords = {Convolutional Neural Network,Deep Neural Network,Ground Truth,Input Image,Mitotic Nucleus},
  file = {/home/david/Zotero/storage/2XVR4SD2/Cireşan et al. - 2013 - Mitosis Detection in Breast Cancer Histology Image.pdf}
}

@article{Dreyfus1973383,
  type = {Article},
  title = {The Computational Solution of Optimal Control Problems with Time Lag},
  author = {Dreyfus, Stuart E.},
  year = {1973},
  journal = {IEEE Transactions on Automatic Control},
  volume = {18},
  number = {4},
  pages = {383--385},
  doi = {10.1109/TAC.1973.1100330},
  publication_stage = {Final},
  source = {Scopus},
  note = {Cited by: 32}
}

@article{elizondoLinearSeparabilityProblem2006,
  title = {The {{Linear Separability Problem}}: {{Some Testing Methods}}},
  shorttitle = {The {{Linear Separability Problem}}},
  author = {Elizondo, D.},
  year = {2006},
  month = mar,
  journal = {IEEE Transactions on Neural Networks},
  volume = {17},
  number = {2},
  pages = {330--344},
  issn = {1045-9227},
  doi = {10.1109/TNN.2005.860871},
  abstract = {The notion of linear separability is used widely in machine learning research. Learning algorithms that use this concept to learn include neural networks (single layer perceptron and recursive deterministic perceptron), and kernel machines (support vector machines). This paper presents an overview of several of the methods for testing linear separability between two classes. The methods are divided into four groups: Those based on linear programming, those based on computational geometry, one based on neural networks, and one based on quadratic programming. The Fisher linear discriminant method is also presented. A section on the quantification of the complexity of classification problems is included.},
  langid = {english},
  file = {/home/david/Zotero/storage/JX227D5E/Elizondo - 2006 - The Linear Separability Problem Some Testing Meth.pdf}
}

@article{farleySimulationSelforganizingSystems1954,
  title = {Simulation of Self-Organizing Systems by Digital Computer},
  author = {Farley, B. and Clark, W.},
  year = {1954},
  journal = {Transactions of the IRE Professional Group on Information Theory},
  volume = {4},
  number = {4},
  pages = {76--84},
  doi = {10.1109/TIT.1954.1057468}
}

@article{guRecentAdvancesConvolutional2018,
  title = {Recent Advances in Convolutional Neural Networks},
  author = {Gu, Jiuxiang and Wang, Zhenhua and Kuen, Jason and Ma, Lianyang and Shahroudy, Amir and Shuai, Bing and Liu, Ting and Wang, Xingxing and Wang, Gang and Cai, Jianfei and Chen, Tsuhan},
  year = {2018},
  month = may,
  journal = {Pattern Recognition},
  volume = {77},
  pages = {354--377},
  issn = {0031-3203},
  doi = {10.1016/j.patcog.2017.10.013},
  abstract = {In the last few years, deep learning has led to very good performance on a variety of problems, such as visual recognition, speech recognition and natural language processing. Among different types of deep neural networks, convolutional neural networks have been most extensively studied. Leveraging on the rapid growth in the amount of the annotated data and the great improvements in the strengths of graphics processor units, the research on convolutional neural networks has been emerged swiftly and achieved state-of-the-art results on various tasks. In this paper, we provide a broad survey of the recent advances in convolutional neural networks. We detailize the improvements of CNN on different aspects, including layer design, activation function, loss function, regularization, optimization and fast computation. Besides, we also introduce various applications of convolutional neural networks in computer vision, speech and natural language processing.},
  langid = {english},
  keywords = {Convolutional neural network,Deep learning},
  file = {/home/david/Zotero/storage/DCGZR9BV/Gu et al. - 2018 - Recent advances in convolutional neural networks.pdf;/home/david/Zotero/storage/HNN7RX6S/S0031320317304120.html}
}

@article{haenleinBriefHistoryArtificial2019,
  title = {A {{Brief History}} of {{Artificial Intelligence}}: {{On}} the {{Past}}, {{Present}}, and {{Future}} of {{Artificial Intelligence}}},
  shorttitle = {A {{Brief History}} of {{Artificial Intelligence}}},
  author = {Haenlein, Michael and Kaplan, Andreas},
  year = {2019},
  month = jul,
  journal = {California Management Review},
  volume = {61},
  pages = {000812561986492},
  doi = {10.1177/0008125619864925},
  abstract = {This introduction to this special issue discusses artificial intelligence (AI), commonly defined as ``a system's ability to interpret external data correctly, to learn from such data, and to use those learnings to achieve specific goals and tasks through flexible adaptation.'' It summarizes seven articles published in this special issue that present a wide variety of perspectives on AI, authored by several of the world's leading experts and specialists in AI. It concludes by offering a comprehensive outlook on the future of AI, drawing on micro-, meso-, and macro-perspectives.},
  file = {/home/david/Zotero/storage/GFIB753Q/Haenlein and Kaplan - 2019 - A Brief History of Artificial Intelligence On the.pdf}
}

@book{hebbOrganizationBehaviorNeuropsychological1949,
  title = {The {{Organization}} of {{Behavior}}: {{A Neuropsychological Theory}}},
  shorttitle = {The {{Organization}} of {{Behavior}}},
  author = {Hebb, Donald Olding},
  year = {1949},
  publisher = {{Wiley}},
  abstract = {Description du ph\'enom\`ene neuropsychologique r\'egissant le laps de temps entre le stimulus et la r\'eponse, le neurophysiologique et le psychologique. Que ce passe-t-il durant cet interval, dans le cervau humain?},
  googlebooks = {dZ0eDiLTwuEC},
  isbn = {978-0-471-36727-7},
  langid = {english}
}

@article{hochreiterLongShortTermMemory1997,
  title = {Long {{Short-Term Memory}}},
  author = {Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  year = {1997},
  month = nov,
  journal = {Neural Computation},
  volume = {9},
  number = {8},
  pages = {1735--1780},
  issn = {0899-7667},
  doi = {10.1162/neco.1997.9.8.1735},
  abstract = {Learning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiter's (1991) analysis of this problem, then address it by introducing a novel, efficient, gradient based method called long short-term memory (LSTM). Truncating the gradient where this does not do harm, LSTM can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units. Multiplicative gate units learn to open and close access to the constant error flow. LSTM is local in space and time; its computational complexity per time step and weight is O. 1. Our experiments with artificial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with real-time recurrent learning, back propagation through time, recurrent cascade correlation, Elman nets, and neural sequence chunking, LSTM leads to many more successful runs, and learns much faster. LSTM also solves complex, artificial long-time-lag tasks that have never been solved by previous recurrent network algorithms.}
}

@article{ivakhnenkoCyberneticPredictingDevices,
  title = {Cybernetic {{Predicting Devices}}},
  author = {Ivakhnenko, A G and Lapa, V G},
  langid = {english},
  file = {/home/david/Zotero/storage/5DSPZAUF/Ivakhnenko and Lapa - Cybernetic Predicting Devices.pdf}
}

@book{josephContributionsPerceptronTheory1960,
  title = {Contributions to {{Perceptron Theory}}},
  author = {Joseph, Roger David},
  year = {1960},
  publisher = {{Cornell Aeronautical Laboratory}},
  googlebooks = {O9JUAAAAYAAJ},
  langid = {english}
}

@article{khanSurveyRecentArchitectures2020,
  title = {A Survey of the Recent Architectures of Deep Convolutional Neural Networks},
  author = {Khan, Asifullah and Sohail, Anabia and Zahoora, Umme and Qureshi, Aqsa Saeed},
  year = {2020},
  month = dec,
  journal = {Artificial Intelligence Review},
  volume = {53},
  number = {8},
  pages = {5455--5516},
  issn = {1573-7462},
  doi = {10.1007/s10462-020-09825-6},
  abstract = {Deep Convolutional Neural Network (CNN) is a special type of Neural Networks, which has shown exemplary performance on several competitions related to Computer Vision and Image Processing. Some of the exciting application areas of CNN include Image Classification and Segmentation, Object Detection, Video Processing, Natural Language Processing, and Speech Recognition. The powerful learning ability of deep CNN is primarily due to the use of multiple feature extraction stages that can automatically learn representations from the data. The availability of a large amount of data and improvement in the hardware technology has accelerated the research in CNNs, and recently interesting deep CNN architectures have been reported. Several inspiring ideas to bring advancements in CNNs have been explored, such as the use of different activation and loss functions, parameter optimization, regularization, and architectural innovations. However, the significant improvement in the representational capacity of the deep CNN is achieved through architectural innovations. Notably, the ideas of exploiting spatial and channel information, depth and width of architecture, and multi-path information processing have gained substantial attention. Similarly, the idea of using a block of layers as a structural unit is also gaining popularity. This survey thus focuses on the intrinsic taxonomy present in the recently reported deep CNN architectures and, consequently, classifies the recent innovations in CNN architectures into seven different categories. These seven categories are based on spatial exploitation, depth, multi-path, width, feature-map exploitation, channel boosting, and attention. Additionally, the elementary understanding of CNN components, current challenges, and applications of CNN are also provided.},
  langid = {english},
  file = {/home/david/Zotero/storage/TIG3U4K3/Khan et al. - 2020 - A survey of the recent architectures of deep convo.pdf}
}

@inproceedings{krizhevskyImageNetClassificationDeep2012,
  title = {{{ImageNet Classification}} with {{Deep Convolutional Neural Networks}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  year = {2012},
  volume = {25},
  publisher = {{Curran Associates, Inc.}},
  abstract = {We trained a large, deep convolutional neural network to classify the 1.3 million high-resolution images in the LSVRC-2010 ImageNet training set into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 39.7\textbackslash\% and 18.9\textbackslash\% which is considerably better than the previous state-of-the-art results. The neural network, which has 60 million parameters and 500,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and two globally connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of convolutional nets. To reduce overfitting in the globally connected layers we employed a new regularization method that proved to be very effective.},
  file = {/home/david/Zotero/storage/PI6EC7PZ/Krizhevsky et al. - 2012 - ImageNet Classification with Deep Convolutional Ne.pdf}
}

@article{lecunDeepLearning2015,
  title = {Deep Learning},
  author = {LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  year = {2015},
  month = may,
  journal = {Nature},
  volume = {521},
  number = {7553},
  pages = {436--444},
  issn = {0028-0836, 1476-4687},
  doi = {10.1038/nature14539},
  langid = {english},
  file = {/home/david/Zotero/storage/FUTB2UE9/nature14539.pdf}
}

@article{lecunGradientBasedLearningApplied1998,
  title = {Gradient-{{Based Learning Applied}} to {{Document Recognition}}},
  author = {LeCun, Yann and Bottou, Leon and Bengio, Yoshua and Ha, Patrick},
  year = {1998},
  langid = {english},
  file = {/home/david/Zotero/storage/VQIWJ4R7/LeCun et al. - 1998 - Gradient-Based Learning Applied to Document Recogn.pdf}
}

@phdthesis{linnainmaa1970representation,
  title = {The Representation of the Cumulative Rounding Error of an Algorithm as a {{Taylor}} Expansion of the Local Rounding Errors},
  author = {Linnainmaa, Seppo},
  year = {1970},
  school = {Master's Thesis (in Finnish), Univ. Helsinki}
}

@article{liSurveyConvolutionalNeural2022,
  title = {A {{Survey}} of {{Convolutional Neural Networks}}: {{Analysis}}, {{Applications}}, and {{Prospects}}},
  shorttitle = {A {{Survey}} of {{Convolutional Neural Networks}}},
  author = {Li, Zewen and Liu, Fan and Yang, Wenjie and Peng, Shouheng and Zhou, Jun},
  year = {2022},
  month = dec,
  journal = {IEEE Transactions on Neural Networks and Learning Systems},
  volume = {33},
  number = {12},
  pages = {6999--7019},
  issn = {2162-2388},
  doi = {10.1109/TNNLS.2021.3084827},
  abstract = {A convolutional neural network (CNN) is one of the most significant networks in the deep learning field. Since CNN made impressive achievements in many areas, including but not limited to computer vision and natural language processing, it attracted much attention from both industry and academia in the past few years. The existing reviews mainly focus on CNN's applications in different scenarios without considering CNN from a general perspective, and some novel ideas proposed recently are not covered. In this review, we aim to provide some novel ideas and prospects in this fast-growing field. Besides, not only 2-D convolution but also 1-D and multidimensional ones are involved. First, this review introduces the history of CNN. Second, we provide an overview of various convolutions. Third, some classic and advanced CNN models are introduced; especially those key points making them reach state-of-the-art results. Fourth, through experimental analysis, we draw some conclusions and provide several rules of thumb for functions and hyperparameter selection. Fifth, the applications of 1-D, 2-D, and multidimensional convolution are covered. Finally, some open issues and promising directions for CNN are discussed as guidelines for future work.},
  keywords = {Computer vision,Convolutional neural networks,convolutional neural networks (CNNs),deep learning,Deep learning,deep neural networks,Feature extraction,Neurons},
  file = {/home/david/Zotero/storage/3JWJ27JB/Li et al. - 2022 - A Survey of Convolutional Neural Networks Analysi.pdf;/home/david/Zotero/storage/47ITFL48/stamp.html}
}

@article{mccarthyPROPOSALDARTMOUTHSUMMER,
  title = {A {{PROPOSAL FOR THE DARTMOUTH SUMMER RESEARCH PROJECT ON ARTIFICIAL INTELLIGENCE}}},
  author = {McCarthy, J and Minsky, M L and Rochester, N and Corporation, I B M and Shannon, C E},
  langid = {english},
  file = {/home/david/Zotero/storage/3BPHNKVQ/McCarthy et al. - A PROPOSAL FOR THE DARTMOUTH SUMMER RESEARCH PROJE.pdf}
}

@article{mccullochLOGICALCALCULUSIDEAS,
  title = {A {{LOGICAL CALCULUS OF THE IDEAS IMMANENT IN NERVOUS ACTIVITY}}},
  author = {Mcculloch, Warren S and Pitts, Walter},
  langid = {english},
  file = {/home/david/Zotero/storage/7MBILWB3/Mcculloch and Pitts - A LOGICAL CALCULUS OF THE IDEAS IMMANENT IN NERVOU.pdf}
}

@book{minsky69perceptrons,
  title = {Perceptrons: {{An}} Introduction to Computational Geometry},
  author = {Minsky, Marvin and Papert, Seymour},
  year = {1969},
  publisher = {{MIT Press}},
  address = {{Cambridge, MA, USA}},
  added-at = {2008-05-16T13:57:01.000+0200},
  description = {: mf : blob : \guillemotright{} bibtex},
  interhash = {d80d4948a422623047f1b800272c0389},
  intrahash = {06a5a6751b3e61408455fca2ed8d87fc},
  keywords = {linear-classification neural-networks seminal},
  timestamp = {2008-05-16T13:57:02.000+0200}
}

@inproceedings{newell1959report,
  title = {Report on a General Problem Solving Program},
  booktitle = {{{IFIP}} Congress},
  author = {Newell, Allen and Shaw, John C and Simon, Herbert A},
  year = {1959},
  volume = {256},
  pages = {64},
  organization = {{Pittsburgh, PA}}
}

@article{ohGPUImplementationNeural2004,
  title = {{{GPU}} Implementation of Neural Networks},
  author = {Oh, Kyoung-Su and Jung, Keechul},
  year = {2004},
  month = jun,
  journal = {Pattern Recognition},
  volume = {37},
  number = {6},
  pages = {1311--1314},
  issn = {0031-3203},
  doi = {10.1016/j.patcog.2004.01.013},
  abstract = {Graphics processing unit (GPU) is used for a faster artificial neural network. It is used to implement the matrix multiplication of a neural network to enhance the time performance of a text detection system. Preliminary results produced a 20-fold performance enhancement using an ATI RADEON 9700 PRO board. The parallelism of a GPU is fully utilized by accumulating a lot of input feature vectors and weight vectors, then converting the many inner-product operations into one matrix operation. Further research areas include benchmarking the performance with various hardware and GPU-aware learning algorithms.},
  keywords = {Graphics processing unit(GPU),Multi-layer perceptron,Neural network(NN),Text detection}
}

@inproceedings{rainaLargescaleDeepUnsupervised2009b,
  title = {Large-Scale Deep Unsupervised Learning Using Graphics Processors},
  booktitle = {Proceedings of the 26th {{Annual International Conference}} on {{Machine Learning}}},
  author = {Raina, Rajat and Madhavan, Anand and Ng, Andrew Y.},
  year = {2009},
  month = jun,
  series = {{{ICML}} '09},
  pages = {873--880},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/1553374.1553486},
  abstract = {The promise of unsupervised learning methods lies in their potential to use vast amounts of unlabeled data to learn complex, highly nonlinear models with millions of free parameters. We consider two well-known unsupervised learning models, deep belief networks (DBNs) and sparse coding, that have recently been applied to a flurry of machine learning applications (Hinton \& Salakhutdinov, 2006; Raina et al., 2007). Unfortunately, current learning algorithms for both models are too slow for large-scale applications, forcing researchers to focus on smaller-scale models, or to use fewer training examples. In this paper, we suggest massively parallel methods to help resolve these problems. We argue that modern graphics processors far surpass the computational capabilities of multicore CPUs, and have the potential to revolutionize the applicability of deep unsupervised learning methods. We develop general principles for massively parallelizing unsupervised learning tasks using graphics processors. We show that these principles can be applied to successfully scaling up learning algorithms for both DBNs and sparse coding. Our implementation of DBN learning is up to 70 times faster than a dual-core CPU implementation for large models. For example, we are able to reduce the time required to learn a four-layer DBN with 100 million free parameters from several weeks to around a single day. For sparse coding, we develop a simple, inherently parallel algorithm, that leads to a 5 to 15-fold speedup over previous methods.},
  isbn = {978-1-60558-516-1},
  file = {/home/david/Zotero/storage/QDRZR76Z/Raina et al. - 2009 - Large-scale deep unsupervised learning using graph.pdf}
}

@inproceedings{ranzatoEfficientLearningSparse2006,
  title = {Efficient {{Learning}} of {{Sparse Representations}} with an {{Energy-Based Model}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {aurelio Ranzato, Marc' and Poultney, Christopher and Chopra, Sumit and Cun, Yann},
  year = {2006},
  volume = {19},
  publisher = {{MIT Press}},
  abstract = {We describe a novel unsupervised method for learning sparse, overcomplete features. The model uses a linear encoder, and a linear decoder preceded by a sparsifying non-linearity that turns a code vector into a quasi-binary sparse code vector. Given an input, the optimal code minimizes the distance between the output of the decoder and the input patch while being as similar as possible to the encoder output. Learning proceeds in a two-phase EM-like fashion: (1) compute the minimum-energy code vector, (2) adjust the parameters of the encoder and decoder so as to decrease the energy. The model produces "stroke detectors" when trained on handwritten numerals, and Gabor-like filters when trained on natural image patches. Inference and learning are very fast, requiring no preprocessing, and no expensive sampling. Using the proposed unsupervised method to initialize the first layer of a convolutional network, we achieved an error rate slightly lower than the best reported result on the MNIST dataset. Finally, an extension of the method is described to learn topographical filter maps.},
  file = {/home/david/Zotero/storage/ZAKI3IQG/Ranzato et al. - 2006 - Efficient Learning of Sparse Representations with .pdf}
}

@article{rochesterTestsCellAssembly1956,
  title = {Tests on a Cell Assembly Theory of the Action of the Brain, Using a Large Digital Computer},
  author = {Rochester, N. and Holland, J. and Haibt, L. and Duda, W.},
  year = {1956},
  journal = {IRE Transactions on Information Theory},
  volume = {2},
  number = {3},
  pages = {80--93},
  doi = {10.1109/TIT.1956.1056810}
}

@article{rosenblattPerceptronProbabilisticModel1958,
  title = {The Perceptron: {{A}} Probabilistic Model for Information Storage and Organization in the Brain.},
  author = {Rosenblatt, F.},
  year = {1958},
  journal = {Psychological Review},
  volume = {65},
  pages = {386--408},
  publisher = {{American Psychological Association}},
  address = {{US}},
  issn = {1939-1471(Electronic),0033-295X(Print)},
  doi = {10.1037/h0042519},
  abstract = {To answer the questions of how information about the physical world is sensed, in what form is information remembered, and how does information retained in memory influence recognition and behavior, a theory is developed for a hypothetical nervous system called a perceptron. The theory serves as a bridge between biophysics and psychology. It is possible to predict learning curves from neurological variables and vice versa. The quantitative statistical approach is fruitful in the understanding of the organization of cognitive systems. 18 references. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  keywords = {*Brain,*Cognition,*Memory,Nervous System}
}

@book{rosenblattPrinciplesNeurodynamicsPerceptrons1962,
  title = {Principles of {{Neurodynamics}}: {{Perceptrons}} and the {{Theory}} of {{Brain Mechanisms}}},
  shorttitle = {Principles of {{Neurodynamics}}},
  author = {Rosenblatt, Frank},
  year = {1962},
  publisher = {{Spartan Books}},
  googlebooks = {7FhRAAAAMAAJ},
  langid = {english}
}

@misc{rumelhart1986learning,
  title = {Learning Internal Representations by Error Propagation", in\textbackslash{{Parallel Distributed Processing}}", {{DE}} Rumelhart, {{JL McClelland}} Eds},
  author = {Rumelhart, DE and Hinton, GE and Williams, RJ},
  year = {1986},
  publisher = {{MIT Press, Cambridge}}
}

@article{schmidhuberDeepLearningNeural2015,
  title = {Deep Learning in Neural Networks: {{An}} Overview},
  shorttitle = {Deep Learning in Neural Networks},
  author = {Schmidhuber, J{\"u}rgen},
  year = {2015},
  month = jan,
  journal = {Neural Networks},
  volume = {61},
  pages = {85--117},
  issn = {08936080},
  doi = {10.1016/j.neunet.2014.09.003},
  abstract = {In recent years, deep artificial neural networks (including recurrent ones) have won numerous contests in pattern recognition and machine learning. This historical survey compactly summarizes relevant work, much of it from the previous millennium. Shallow and Deep Learners are distinguished by the depth of their credit assignment paths, which are chains of possibly learnable, causal links between actions and effects. I review deep supervised learning (also recapitulating the history of backpropagation), unsupervised learning, reinforcement learning \& evolutionary computation, and indirect search for short programs encoding deep and large networks.},
  langid = {english},
  file = {/home/david/Zotero/storage/PT65D7X6/Schmidhuber - 2015 - Deep learning in neural networks An overview.pdf}
}

@inproceedings{simardBestPracticesConvolutional2003,
  title = {Best Practices for Convolutional Neural Networks Applied to Visual Document Analysis},
  booktitle = {Seventh {{International Conference}} on {{Document Analysis}} and {{Recognition}}, 2003. {{Proceedings}}.},
  author = {Simard, P.Y. and Steinkraus, D. and Platt, J.C.},
  year = {2003},
  volume = {1},
  pages = {958--963},
  publisher = {{IEEE Comput. Soc}},
  address = {{Edinburgh, UK}},
  doi = {10.1109/ICDAR.2003.1227801},
  abstract = {Neural networks are a powerful technology for classification of visual inputs arising from documents. However, there is a confusing plethora of different neural network methods that are used in the literature and in industry. This paper describes a set of concrete best practices that document analysis researchers can use to get good results with neural networks. The most important practice is getting a training set as large as possible: we expand the training set by adding a new form of distorted data. The next most important practice is that convolutional neural networks are better suited for visual document tasks than fully connected networks. We propose that a simple ``do-it-yourself'' implementation of convolution with a flexible architecture is suitable for many visual document problems. This simple convolutional neural network does not require complex methods, such as momentum, weight decay, structuredependent learning rates, averaging layers, tangent prop, or even finely-tuning the architecture. The end result is a very simple yet general architecture which can yield state-of-the-art performance for document analysis. We illustrate our claims on the MNIST set of English digit images.},
  isbn = {978-0-7695-1960-9},
  langid = {english},
  file = {/home/david/Zotero/storage/M3Z6FERC/Simard et al. - 2003 - Best practices for convolutional neural networks a.pdf}
}

@article{stallkampManVsComputer2012,
  title = {Man vs. Computer: {{Benchmarking}} Machine Learning Algorithms for Traffic Sign Recognition},
  shorttitle = {Man vs. Computer},
  author = {Stallkamp, J. and Schlipsing, M. and Salmen, J. and Igel, C.},
  year = {2012},
  month = aug,
  journal = {Neural Networks},
  series = {Selected {{Papers}} from {{IJCNN}} 2011},
  volume = {32},
  pages = {323--332},
  issn = {0893-6080},
  doi = {10.1016/j.neunet.2012.02.016},
  abstract = {Traffic signs are characterized by a wide variability in their visual appearance in real-world environments. For example, changes of illumination, varying weather conditions and partial occlusions impact the perception of road signs. In practice, a large number of different sign classes needs to be recognized with very high accuracy. Traffic signs have been designed to be easily readable for humans, who perform very well at this task. For computer systems, however, classifying traffic signs still seems to pose a challenging pattern recognition problem. Both image processing and machine learning algorithms are continuously refined to improve on this task. But little systematic comparison of such systems exist. What is the status quo? Do today's algorithms reach human performance? For assessing the performance of state-of-the-art machine learning algorithms, we present a publicly available traffic sign dataset with more than 50,000 images of German road signs in 43 classes. The data was considered in the second stage of the German Traffic Sign Recognition Benchmark held at IJCNN 2011. The results of this competition are reported and the best-performing algorithms are briefly described. Convolutional neural networks (CNNs) showed particularly high classification accuracies in the competition. We measured the performance of human subjects on the same data\textemdash and the CNNs outperformed the human test persons.},
  langid = {english},
  keywords = {Benchmarking,Convolutional neural networks,Machine learning,Traffic sign recognition},
  file = {/home/david/Zotero/storage/F7DQ68KG/Stallkamp et al. - 2012 - Man vs. computer Benchmarking machine learning al.pdf;/home/david/Zotero/storage/W7ICGVVM/S0893608012000457.html}
}

@inproceedings{taigmanDeepFaceClosingGap2014,
  title = {{{DeepFace}}: {{Closing}} the {{Gap}} to {{Human-Level Performance}} in {{Face Verification}}},
  shorttitle = {{{DeepFace}}},
  booktitle = {2014 {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  author = {Taigman, Yaniv and Yang, Ming and Ranzato, Marc'Aurelio and Wolf, Lior},
  year = {2014},
  month = jun,
  pages = {1701--1708},
  publisher = {{IEEE}},
  address = {{Columbus, OH, USA}},
  doi = {10.1109/CVPR.2014.220},
  abstract = {In modern face recognition, the conventional pipeline consists of four stages: detect {$\Rightarrow$} align {$\Rightarrow$} represent {$\Rightarrow$} classify. We revisit both the alignment step and the representation step by employing explicit 3D face modeling in order to apply a piecewise affine transformation, and derive a face representation from a nine-layer deep neural network. This deep network involves more than 120 million parameters using several locally connected layers without weight sharing, rather than the standard convolutional layers. Thus we trained it on the largest facial dataset to-date, an identity labeled dataset of four million facial images belonging to more than 4,000 identities. The learned representations coupling the accurate model-based alignment with the large facial database generalize remarkably well to faces in unconstrained environments, even with a simple classifier. Our method reaches an accuracy of 97.35\% on the Labeled Faces in the Wild (LFW) dataset, reducing the error of the current state of the art by more than 27\%, closely approaching human-level performance.},
  isbn = {978-1-4799-5118-5},
  langid = {english},
  file = {/home/david/Zotero/storage/VD86KSFJ/Taigman et al. - 2014 - DeepFace Closing the Gap to Human-Level Performan.pdf}
}

@misc{tompsonEfficientObjectLocalization2015,
  title = {Efficient {{Object Localization Using Convolutional Networks}}},
  author = {Tompson, Jonathan and Goroshin, Ross and Jain, Arjun and LeCun, Yann and Bregler, Christopher},
  year = {2015},
  month = jun,
  number = {arXiv:1411.4280},
  eprint = {1411.4280},
  eprinttype = {arxiv},
  primaryclass = {cs},
  publisher = {{arXiv}},
  abstract = {Recent state-of-the-art performance on human-body pose estimation has been achieved with Deep Convolutional Networks (ConvNets). Traditional ConvNet architectures include pooling and sub-sampling layers which reduce computational requirements, introduce invariance and prevent over-training. These benefits of pooling come at the cost of reduced localization accuracy. We introduce a novel architecture which includes an efficient `position refinement' model that is trained to estimate the joint offset location within a small region of the image. This refinement model is jointly trained in cascade with a state-of-the-art ConvNet model to achieve improved accuracy in human joint location estimation. We show that the variance of our detector approaches the variance of human annotations on the FLIC dataset and outperforms all existing approaches on the MPII-human-pose dataset.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  note = {Comment: 8 pages with 1 page of citations},
  file = {/home/david/Zotero/storage/GFPQBARK/Tompson et al. - 2015 - Efficient Object Localization Using Convolutional .pdf;/home/david/Zotero/storage/MZWM9I3V/1411.html}
}

@article{turingCOMPUTINGMACHINERYINTELLIGENCE1950,
  title = {I.\textemdash{{COMPUTING MACHINERY AND INTELLIGENCE}}},
  author = {Turing, A. M.},
  year = {1950},
  month = oct,
  journal = {Mind},
  volume = {LIX},
  number = {236},
  pages = {433--460},
  issn = {1460-2113, 0026-4423},
  doi = {10.1093/mind/LIX.236.433},
  langid = {english},
  file = {/storage/Master Thesis/Articles/lix-236-433.pdf}
}

@inproceedings{wangGenCNNConvolutionalArchitecture2015,
  title = {{{genCNN}}: {{A Convolutional Architecture}} for {{Word Sequence Prediction}}},
  shorttitle = {{{genCNN}}},
  booktitle = {Proceedings of the 53rd {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}} and the 7th {{International Joint Conference}} on {{Natural Language Processing}} ({{Volume}} 1: {{Long Papers}})},
  author = {Wang, Mingxuan and Lu, Zhengdong and Li, Hang and Jiang, Wenbin and Liu, Qun},
  year = {2015},
  month = jul,
  pages = {1567--1576},
  publisher = {{Association for Computational Linguistics}},
  address = {{Beijing, China}},
  doi = {10.3115/v1/P15-1151},
  file = {/home/david/Zotero/storage/XWPUUAPS/Wang et al. - 2015 - genCNN A Convolutional Architecture for Word Sequ.pdf}
}

@article{weizenbaumELIZAComputerProgram1966,
  title = {{{ELIZA}}\textemdash a Computer Program for the Study of Natural Language Communication between Man and Machine},
  author = {Weizenbaum, Joseph},
  year = {1966},
  month = jan,
  journal = {Communications of the ACM},
  volume = {9},
  number = {1},
  pages = {36--45},
  issn = {0001-0782},
  doi = {10.1145/365153.365168},
  file = {/home/david/Zotero/storage/3SAM3JPS/Weizenbaum - 1966 - ELIZA—a computer program for the study of natural .pdf}
}

@inproceedings{wengCresceptronSelforganizingNeural1992,
  title = {Cresceptron: A Self-Organizing Neural Network Which Grows Adaptively},
  shorttitle = {Cresceptron},
  booktitle = {[{{Proceedings}} 1992] {{IJCNN International Joint Conference}} on {{Neural Networks}}},
  author = {Weng, J. and Ahuja, N. and Huang, T.S.},
  year = {1992},
  month = jun,
  volume = {1},
  pages = {576-581 vol.1},
  doi = {10.1109/IJCNN.1992.287150},
  abstract = {Cresceptron uses a hierarchical framework to grow neural networks automatically, adaptively, and incrementally through learning. At every level of the hierarchy, new concepts are detected automatically and the network grows by creating new neurons and synapses which memorize the new concepts and their context. The training samples are generalized to other perceptually equivalent items through hierarchical tolerance of deviation. The neural network recognizes the learned items and their variations by hierarchically associating the learned knowledge with the input. It segments the recognized items from the input through back training along the response paths.{$<>$}},
  keywords = {Backpropagation,Electric breakdown,Humans,Input variables,Learning systems,Neural networks,Neurons,Unsupervised learning},
  file = {/home/david/Zotero/storage/PXM2V4HZ/Weng et al. - 1992 - Cresceptron a self-organizing neural network whic.pdf;/home/david/Zotero/storage/9EQZD6A9/stamp.html}
}

@article{xiangConvolutionalNeuralNetworkbased2020,
  title = {A Convolutional Neural Network-Based Linguistic Steganalysis for Synonym Substitution Steganography},
  author = {Xiang, Lingyun and Guo, Guoqing and Yu, Jingming and Sheng, Victor S. and Yang, Peng and Xiang, Lingyun and Guo, Guoqing and Yu, Jingming and Sheng, Victor S. and Yang, Peng},
  year = {2020},
  journal = {Mathematical Biosciences and Engineering},
  volume = {17},
  number = {2},
  pages = {1041--1058},
  issn = {1551-0018},
  doi = {10.3934/mbe.2020055},
  abstract = {In this paper, a linguistic steganalysis method based on two-level cascaded convolutional neural networks (CNNs) is proposed to improve the system's ability to detect stego texts, which are generated via synonym substitutions. The first-level network, sentence-level CNN, consists of one convolutional layer with multiple convolutional kernels in different window sizes, one pooling layer to deal with variable sentence lengths, and one fully connected layer with dropout as well as a softmax output, such that two final steganographic features are obtained for each sentence. The unmodified and modified sentences, along with their words, are represented in the form of pre-trained dense word embeddings, which serve as the input of the network. Sentence-level CNN provides the representation of a sentence, and can thus be utilized to predict whether a sentence is unmodified or has been modified by synonym substitutions. In the second level, a text-level CNN exploits the predicted representations of sentences obtained from the sentence-level CNN to determine whether the detected text is a stego text or cover text. Experimental results indicate that the proposed sentence-level CNN can effectively extract sentence features for sentence-level steganalysis tasks and reaches an average accuracy of 82.245\%. Moreover, the proposed steganalysis method achieves greatly improved detection performance when distinguishing stego texts from cover texts.},
  copyright = {2020 The Author(s)},
  langid = {english},
  annotation = {Cc\_license\_type: cc\_by Primary\_atype: Mathematical Biosciences and Engineering Subject\_term: Research article Subject\_term\_id: Research article}
}

@article{xuMachineLearningConstruction2021,
  title = {Machine Learning in Construction: {{From}} Shallow to Deep Learning},
  shorttitle = {Machine Learning in Construction},
  author = {Xu, Yayin and Zhou, Ying and Sekula, Przemyslaw and Ding, Lieyun},
  year = {2021},
  month = may,
  journal = {Developments in the Built Environment},
  volume = {6},
  pages = {100045},
  issn = {26661659},
  doi = {10.1016/j.dibe.2021.100045},
  abstract = {The development of artificial intelligence technology is currently bringing about new opportunities in construction. Machine learning is a major area of interest within the field of artificial intelligence, playing a pivotal role in the process of making construction ``smart''. The application of machine learning in construction has the potential to open up an array of opportunities such as site supervision, automatic detection, and intelligent maintenance. However, the implementation of machine learning faces a range of challenges due to the difficulties in acquiring labeled data, especially when applied in a highly complex construction site environment. This paper reviews the history of machine learning development from shallow to deep learning and its applications in construction. The strengths and weaknesses of machine learning technology in construction have been analyzed in order to foresee the future direction of machine learning applications in this sphere. Furthermore, this paper presents suggestions which may benefit researchers in terms of combining specific knowledge domains in construction with machine learning algorithms so as to develop dedicated deep network models for the industry.},
  langid = {english},
  file = {/home/david/Zotero/storage/GTU5IIL7/1-s2.0-S2666165921000041-main.pdf}
}

@article{yamashitaConvolutionalNeuralNetworks2018,
  title = {Convolutional Neural Networks: An Overview and Application in Radiology},
  shorttitle = {Convolutional Neural Networks},
  author = {Yamashita, Rikiya and Nishio, Mizuho and Do, Richard Kinh Gian and Togashi, Kaori},
  year = {2018},
  month = aug,
  journal = {Insights into Imaging},
  volume = {9},
  number = {4},
  pages = {611--629},
  publisher = {{SpringerOpen}},
  issn = {1869-4101},
  doi = {10.1007/s13244-018-0639-9},
  abstract = {Convolutional neural network (CNN), a class of artificial neural networks that has become dominant in various computer vision tasks, is attracting interest across a variety of domains, including radiology. CNN is designed to automatically and adaptively learn spatial hierarchies of features through backpropagation by using multiple building blocks, such as convolution layers, pooling layers, and fully connected layers. This review article offers a perspective on the basic concepts of CNN and its application to various radiological tasks, and discusses its challenges and future directions in the field of radiology. Two challenges in applying CNN to radiological tasks, small dataset and overfitting, will also be covered in this article, as well as techniques to minimize them. Being familiar with the concepts and advantages, as well as limitations, of CNN is essential to leverage its potential in diagnostic radiology, with the goal of augmenting the performance of radiologists and improving patient care. \textbullet{} Convolutional neural network is a class of deep learning methods which has become dominant in various computer vision tasks and is attracting interest across a variety of domains, including radiology. \textbullet{} Convolutional neural network is composed of multiple building blocks, such as convolution layers, pooling layers, and fully connected layers, and is designed to automatically and adaptively learn spatial hierarchies of features through a backpropagation algorithm. \textbullet{} Familiarity with the concepts and advantages, as well as limitations, of convolutional neural network is essential to leverage its potential to improve radiologist performance and, eventually, patient care.},
  copyright = {2018 The Author(s)},
  langid = {english},
  file = {/home/david/Zotero/storage/UCQ9XZCM/Yamashita et al. - 2018 - Convolutional neural networks an overview and app.pdf}
}

@inproceedings{Yang2009,
  type = {Conference Paper},
  title = {Detecting Human Actions in Surveillance Videos},
  author = {Yang, Ming and Ji, Shuiwang and Xu, Wei and Wang, Jinjun and Lv, Fengjun and Yu, Kai and Gong, Yihong and Dikmen, Mert and Lin, Dennis J. and Huang, Thomas S.},
  year = {2009},
  series = {2009 {{TREC Video Retrieval Evaluation Notebook Papers}}},
  publication_stage = {Final},
  source = {Scopus},
  note = {Cited by: 26}
}

@inproceedings{zellSimulationNeuronalerNetze1994,
  title = {Simulation Neuronaler {{Netze}}},
  author = {Zell, Andreas},
  year = {1994}
}

@article{zhangImprovedBreastCancer2021,
  title = {Improved {{Breast Cancer Classification Through Combining Graph Convolutional Network}} and {{Convolutional Neural Network}}},
  author = {Zhang, Yu-Dong and Satapathy, Suresh Chandra and Guttery, David S. and G{\'o}rriz, Juan Manuel and Wang, Shui-Hua},
  year = {2021},
  month = mar,
  journal = {Information Processing \& Management},
  volume = {58},
  number = {2},
  pages = {102439},
  issn = {0306-4573},
  doi = {10.1016/j.ipm.2020.102439},
  abstract = {Aim In a pilot study to improve detection of malignant lesions in breast mammograms, we aimed to develop a new method called BDR-CNN-GCN, combining two advanced neural networks: (i) graph convolutional network (GCN); and (ii) convolutional neural network (CNN). Method We utilised a standard 8-layer CNN, then integrated two improvement techniques: (i) batch normalization (BN) and (ii) dropout (DO). Finally, we utilized rank-based stochastic pooling (RSP) to substitute the traditional max pooling. This resulted in BDR-CNN, which is a combination of CNN, BN, DO, and RSP. This BDR-CNN was hybridized with a two-layer GCN, and yielded our BDR-CNN-GCN model which was then utilized for analysis of breast mammograms as a 14-way data augmentation method. Results As proof of concept, we ran our BDR-CNN-GCN algorithm 10 times on the breast mini-MIAS dataset (containing 322 mammographic images), achieving a sensitivity of 96.20{$\pm$}2.90\%, a specificity of 96.00{$\pm$}2.31\% and an accuracy of 96.10{$\pm$}1.60\%. Conclusion Our BDR-CNN-GCN showed improved performance compared to five proposed neural network models and 15 state-of-the-art breast cancer detection approaches, proving to be an effective method for data augmentation and improved detection of malignant breast masses.},
  keywords = {Artificial intelligence,Breast cancer classification,Convolutional neural network,Data augmentation,Deep learning,Graph convolutional network,Mammogram,Rank-based stochastic pooling}
}

@article{zhangStudyArtificialIntelligence2021,
  title = {Study on Artificial Intelligence: {{The}} State of the Art and Future Prospects},
  shorttitle = {Study on Artificial Intelligence},
  author = {Zhang, Caiming and Lu, Yang},
  year = {2021},
  month = sep,
  journal = {Journal of Industrial Information Integration},
  volume = {23},
  pages = {100224},
  issn = {2452414X},
  doi = {10.1016/j.jii.2021.100224},
  abstract = {In the world, the technological and industrial revolution is accelerating by the widespread application of new generation information and communication technologies, such as AI, IoT (the Internet of Things), and blockchain technology. Artificial intelligence has attracted much attention from government, industry, and academia. In this study, popular articles published in recent years that relate to artificial intelligence are selected and explored. This study aims to provide a review of artificial intelligence based on industry information integration. It presents an overview of the scope of artificial intelligence using background, drivers, technologies, and applications, as well as logical opinions regarding the development of artificial intelligence. This paper may play a role in AIrelated research and should provide important insights for practitioners in the real world.The main contribu\- tion of this study is that it clarifies the state of the art of AI for future study.},
  langid = {english},
  file = {/storage/Master Thesis/Articles/1-s2.0-S2452414X21000248-main.pdf}
}

@misc{zhuBCNNBranchConvolutional2017,
  title = {B-{{CNN}}: {{Branch Convolutional Neural Network}} for {{Hierarchical Classification}}},
  shorttitle = {B-{{CNN}}},
  author = {Zhu, Xinqi and Bain, Michael},
  year = {2017},
  month = oct,
  number = {arXiv:1709.09890},
  eprint = {1709.09890},
  eprinttype = {arxiv},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1709.09890},
  abstract = {Convolutional Neural Network (CNN) image classifiers are traditionally designed to have sequential convolutional layers with a single output layer. This is based on the assumption that all target classes should be treated equally and exclusively. However, some classes can be more difficult to distinguish than others, and classes may be organized in a hierarchy of categories. At the same time, a CNN is designed to learn internal representations that abstract from the input data based on its hierarchical layered structure. So it is natural to ask if an inverse of this idea can be applied to learn a model that can predict over a classification hierarchy using multiple output layers in decreasing order of class abstraction. In this paper, we introduce a variant of the traditional CNN model named the Branch Convolutional Neural Network (B-CNN). A B-CNN model outputs multiple predictions ordered from coarse to fine along the concatenated convolutional layers corresponding to the hierarchical structure of the target classes, which can be regarded as a form of prior knowledge on the output. To learn with B-CNNs a novel training strategy, named the Branch Training strategy (BT-strategy), is introduced which balances the strictness of the prior with the freedom to adjust parameters on the output layers to minimize the loss. In this way we show that CNN based models can be forced to learn successively coarse to fine concepts in the internal layers at the output stage, and that hierarchical prior knowledge can be adopted to boost CNN models' classification performance. Our models are evaluated to show that the B-CNN extensions improve over the corresponding baseline CNN on the benchmark datasets MNIST, CIFAR-10 and CIFAR-100.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  note = {Comment: 9 pages, 8 figures},
  file = {/home/david/Zotero/storage/GUGKM2JP/Zhu and Bain - 2017 - B-CNN Branch Convolutional Neural Network for Hie.pdf;/home/david/Zotero/storage/GIA2V3AC/1709.html}
}
